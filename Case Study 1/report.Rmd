---
title: |
    | Planejamento e Análise de Experimentos (EEE933)
    | Estudo de Caso 1
#title: Planejamento e Análise de Experimentos (EEE933) Estudo de Caso 1
author: Pedro Vinícius, Samara Silva e Savio Vieira
date: 10 de Agosto de 2020
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: yes
indent: true
header-includes: 
    - \usepackage{indentfirst}
bibliography: ref.bib
doi: https://github.com/pedbrgs/Design-and-Analysis-of-Experiments
pagetitle: Estudo de Caso 1
---

```{r setup,results='hide',warning=FALSE,echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away. 
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
      }
if (!require(ExpDE, quietly = TRUE)){
      install.packages("ExpDE")
      }
```


```{r, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
# ExpDE package (it was built under R version 3.6.1)
library(ExpDE)
# Statistical package
library(stats)
# Ggplot2 package
library(ggplot2)
# Plotly package
library(plotly)
```

# Introdução

<!--
Lindsey (1996) define inferência estatística como o campo que se preocupa com o processo probabilístico relacionado a eventos já ocorridos e às ilações sobre a população que pode-se chegar com base nesse conhecimento, ou seja, trata-se de extrair conclusões para o universo de estudo a partir de observações empíricas ou processos estocásticos.
-->

Uma versão atual de um software conhecido apresenta uma distribuição dos custos de execução com média populacional $\mu_c = 50$ e variância populacional $\sigma^2_c = 100$. Posteriormente, uma nova versão do software é desenvolvida, no qual deseja-se investigar prováveis melhorias de desempenho. Com esse intuito, duas análises estatísticas são propostas: (i) uma sobre o custo médio e (ii) uma sobre a variância do custo.

Para ambos os casos, as hipóteses nulas foram definidas de maneira conservadora, partindo-se do pressuposto de que os parâmetros populacionais conhecidos foram mantidos na nova versão. A partir disso, diversas etapas foram conduzidas até a conclusão dos experimentos, entre elas a coleta de dados da distribuição dos custos do software novo, a análise exploratória dessa amostra, a inferência por meio dos testes estatísticos, a validação das premissas consideradas e as conclusões. As próximas seções contém o detalhamento técnico de cada uma dessas etapas.

```{r, results = 'hide', echo = FALSE}
# ------------ Current version parameters (populational) ------------ #
# Mean
mu_c <- 50
# Standard deviation
sigma_c <- sqrt(100)
# Variance
sigma2_c <- sigma_c^2
```

```{r, results = 'hide', echo = FALSE}
# Desired significance level (Type I error probability)
alpha <- 0.01
# Confidence level
conf_level <- 1 - alpha
# Minimally relevant effect size
delta_star <- 4
# Desired power (statistical power)
pi <- 0.8
# Type II error probability
beta <- 1 - pi

# Assuming equivalence of variances (initial estimate of the variance)
sigma_n <- sigma_c
```

## Parte 1: Teste Sobre o Custo Médio

### Planejamento dos Experimentos

No que se refere a primeira parte do estudo de caso, o teste terá que dispor de um nível de significância $\alpha = 0.01$, um tamanho de efeito de mínima relevância $\delta^* = 4$ e uma potência desejada $\pi = 1 - \beta = 0.8$. As hipóteses estatísticas foram definidas com o intuito de responder às questões propostas abaixo:

* Há alguma diferença entre o custo médio da versão nova do software e o custo médio da versão corrente?
* Caso haja, qual a melhor versão em termos de custo médio?

Em concordância com a proposta de comparação de custo médio entre as versões, as hipóteses de teste podem ser formuladas sobre o parâmetro média:
$$\begin{cases} H_0: \mu_n = 50&\\H_1: \mu_n<50\end{cases}$$
onde a hipótese nula implica na igualdade entre os custos médios das versões e a hipótese alternativa unilateral na superioridade da nova versão em média.

  A fase subsequente desse experimento consiste em gerar uma amostra representativa do desempenho da nova versão do software. Para tal fim, é necessário especificar o tamanho dessa amostra, considerando as propriedades preestabelecidas do teste. A priori, o Poder do Teste é bastante conveniente, porém implica em um grande dilema. O cálculo do tamanho amostral requer uma estimativa da variância, que só é obtida através das observações contidas na amostra. As possibilidades mais práticas de se conduzir o experimento nesse caso são\cite{Campelo2018-LNDoE}:

1. Utilização de conhecimento do problema para se obter uma estimativa (inicial) da variância;
2. Condução do estudo com um tamanho amostral predefinido, como $N = 30$, o que poderia violar a potência desejada;
3. Realização de um estudo piloto para estimar a variância dos dados a partir do tamanho de efeito de mínima relevância $\delta^*$.

Considerando as vantagens e desvantagens de cada uma, optou-se por utilizar a primeira abordagem. Por mais que essa estimativa seja sobre-estimada e os prováveis ganhos não sejam observados ao término do estudo, uma vez que se espera ganhos de variância da nova versão do software em relação à versão atual, pode-se considerar igualdade de variâncias como uma estimativa inicial, ou seja, $\sigma^2_n \approx \sigma^2_c = 100$. Entretanto, essa premissa será avaliada posteriormente na análise exploratória dos dados.

Diante da estimativa inicial da variância amostral, o Poder do Teste pode ser finalmente realizado. Esse teste é originalmente usado para mensurar o controle do teste de hipóteses sobre o erro do tipo II ($\beta$), isto é, $P(\mbox{rejeitar}\ H_0|H_0 \ \mbox{é falso})$. No entanto, tal teste também pode ser utilizado para estimar outros parâmetros amostrais, como tamanho de efeito $\delta^*$, nível de significância $\alpha$, tamanho da amostra $N$, potência $\pi$ e desvio padrão amostral $\sigma_n$ \cite{PowerTest}. 

<!--
Este último, é tido como critério de fundamental importância no planejamento da pesquisa, para reduzir o custo operacional, que é aproximadamente linear (KOCHER, JAFFE, JUN, 1999).
-->

```{r}
# Define the sample size to be used in this experiment
(params <- power.t.test(delta = delta_star,
             sd = sigma_n,
             sig.level = alpha, 
             power = pi,
             type = "one.sample",
             alternative = "one.sided"))

# Number of observations
n <- ceiling(params$n)
```
Assim, tem-se uma estimativa de $N = 66$ observações.


### Coleta dos Dados

Para configurar o procedimento de coleta de dados usamos a função R: ExpDE, essa rotina é usada para iniciar um algoritmo de evolução diferencial para a minimização de uma determinada instância de problema usando diferentes variantes dos operadores de recombinação, mutação e seleção. 
Dessa forma, rodamos n (números de observações da amostra) vezes a função a fim de construir nossa amostra.
A amostra gerada foi salva em um arquivo .csv, que permanecerá sem alterações. Uma vez fixo nossa amostra, permitirá um estudo constante toda vez que compilarmos o codigo estatistico, pois durante a execução do código, carregaremos o .csv da amostra.

```{r}
data_generation <- function(n){
  
  mre <- list(name = "recombination_bin", cr = 0.9)
  mmu <- list(name = "mutation_rand", f = 2)
  mpo <- 100
  mse <- list(name = "selection_standard")
  mst <- list(names = "stop_maxeval", maxevals = 10000)
  mpr <- list(name = "sphere", xmin = -seq(1, 20), xmax = 20 + 5 * seq(5, 24))
  
  sample <- c()
  # Generate n observations
  for (i in 1:n){
    observation <- ExpDE(mpo, mmu, mre, mse, mst, mpr, 
                    showpars = list(show.iters = "none"))$Fbest
    sample <- c(sample, observation)
  }
  
  return(sample)
  
}
```

```{r, results = 'hide', echo = FALSE}
# Random seed
# set.seed(1007)

# Collect the sample with n observations
# sample <- data_generation(n = n)

# Saves data to the csv file
# write.table(sample, file = 'sample.csv', row.names = FALSE, col.names = FALSE)

# Loads data from csv file
sample <- read.csv('sample.csv', header = FALSE)$V1
```

### Análise Exploratória de Dados

A fim de melhor entender nosso cenário de estudo apresentaremos a seguir representações gráficas da nossa amostra.
Primeiro, o histograma, que representa a distribuição da frequência de nossas observações, a partir dos dados quantitativos da nossa amostra, uma aproximação a uma função de densidade probabilística. O histograma é uma boa ferramenta de analise visual do comportamento de amostras em geral, neste caso auxiliando no processo de visualização de características como a media da amostra e variação da distribuição em torno da mesma.  


```{r, echo = FALSE, results = 'hide'}
# ------------ New version parameters (sample) ------------ #
# Mean
mu_n <- mean(sample)
# Standard deviation
sigma_n <- sd(sample)
# Variance
sigma2_n <- var(sample)
```

```{r, fig.height = 3, fig.width = 3, fig.align = 'center'}
# Histogram
histogram <- ggplot(data = as.data.frame(sample), mapping = aes(x = sample))
histogram + geom_histogram(lwd = 0.3, bins = 20, color = 'black', fill = 'gray') +
            scale_x_continuous(name = 'Amostra') + 
            scale_y_continuous(name = 'Frequência')
```
Segundo, o boxplot, uma exibição gráfica que descreve simultaneamente vários recursos importantes de um conjunto de dados, como centro, dispersão, desvio da simetria e identificação de observações de valores incomuns ou outliers. [1] Os boxplots são muito úteis em comparações gráficas entre conjuntos de dados, porque têm alto impacto visual e são fáceis de entender.

```{r, fig.height = 3, fig.width = 3, fig.align = 'center'}
# Boxplot
boxplot <- ggplot(data = as.data.frame(sample), mapping = aes(y = sample))
boxplot + geom_boxplot(lwd = 0.3) + 
          scale_x_continuous(name = 'Amostra') + 
          scale_y_continuous(name = '') + 
          theme(axis.text.x = element_blank())
```
Terceiro, o QQ-plot, usado para comparar duas distribuições de probabilidade. Caso os dados tenham distribuições idênticas, uma linha reta com inclinação um é traçada, e os quantis ao redor da mesma. A densidade com que os pontos são representados indicam a frequência de ocorrência dos mesmos. Para o caso em que as variáveis têm caudas longas, o gráfico Q-Q tende a enfatizar a estrutura comparativa nas caudas e a embaçar as distinções no "meio", onde as densidades são altas. A razão para isso é que o quantil é uma mudança rápida função de p quando a densidade é escassa (nas caudas) e uma função de mudança lenta de p, onde a densidade é alta (no meio). [2]
```{r, fig.height = 3, fig.width = 3, fig.align = 'center'}
# QQ-Plot
qqplot <- ggplot(data = as.data.frame(sample), mapping = aes(sample = sample))
qqplot + geom_qq_line() + 
         geom_qq() + 
         scale_y_continuous(name = 'Amostra') + 
         scale_x_continuous(name = 'Quantil')
```

### Análise Estatística

```{r}
# ------------ Hypothesis Testing ------------ #    
(t_test <- t.test(x = sample, 
                mu = mu_c, 
                alternative = "less",
                conf.level = conf_level))

# Confidence Interval
CI <- t_test$conf.int[1:2]
```

### Validação de Premissas

```{r}
# Wilcoxon Signed-Ranks Test, because it does not assume normality
(wilcoxon_test <- wilcox.test(x = sample,
                alternative = "less",
                mu = mu_c, 
                paired = FALSE, 
                exact = NULL, 
                correct = TRUE,
                conf.int = FALSE, 
                conf.level = conf_level))
```

## Parte 2: Teste Sobre a Variância do Custo

## Planejamento dos Experimentos 

$$\begin{cases} H_0: \sigma^2_n = 100&\\H_1: \sigma^2_n<100\end{cases}$$

```{r, results = 'hide', echo = FALSE}
# Desired significance level (Type I error probability)
alpha <- 0.05
# Confidence level
conf_level <- 1 - alpha
```

### Conclusões

\renewcommand\refname{Referências}
\bibliographystyle{plain}
\bibliography{ref}

<!--
1 - D.C. Montgomery and G.C. Runger, Applied Statistics and Probability for Engineers, Chapter 7. 3rd Ed., Wiley 2005.

2 - Wilk, M.B.; Gnanadesikan, R. (1968). Probability plotting methods for the analysis of data. Biometrika Trust. 55 (1): 1–17.

KOCHER, Paul; JAFFE, Joshua; JUN, Benjamin. Differential Power Analysis. In: Annual international cryptology conference. Springer, Berlin, Heidelberg, 1999. p. 388-397.

LINDSEY, James K. Parametric Statistical Inference. Oxford University Press, 1996.

ExpDE v0.1.4. by Felipe Campelo. CRAN package description, 2018-01-10 10:45:05 UTC. Disponível em: <https://www.rdocumentation.org/packages/ExpDE/versions/0.1.4>. Acesso em: 02 de ago. de 2020.
-->