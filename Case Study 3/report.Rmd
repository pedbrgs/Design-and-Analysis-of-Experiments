---
title: |
    | Planejamento e Análise de Experimentos (EEE933)
    | Estudo de Caso 3
author: Pedro Vinícius, Samara Silva e Savio Vieira
date: 14 de Setembro de 2020
output:
  pdf_document:
    #latex_engine: xelatex
    fig_caption: yes
  html_document:
    df_print: paged
indent: true
header-includes: 
    - \usepackage{indentfirst}
    - \usepackage{float}
    - \usepackage{multicol}
bibliography: ref.bib
doi: https://github.com/pedbrgs/Design-and-Analysis-of-Experiments
pagetitle: Estudo de Caso 3
---

```{r setup, results='hide', warning=FALSE, include = FALSE, message = FALSE, echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away. 
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
}
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(stats, quietly = TRUE)){
      suppressMessages(install.packages("stats"))
      }
if (!require(plotly, quietly = TRUE)){
      suppressMessages(install.packages("plotly"))
      }
if (!require(reshape2, quietly = TRUE)){
      suppressMessages(install.packages("reshape2"))
      }
if (!require(tidyr, quietly = TRUE)){
      suppressMessages(install.packages("tidyr"))
}
if (!require(lsr, quietly = TRUE)){
      suppressMessages(install.packages("lsr"))
      }
if (!require(car, quietly = TRUE)){
      suppressMessages(install.packages("car"))
      }
if (!require(pwr, quietly = TRUE)){
      suppressMessages(install.packages("pwr"))
      }
if (!require(multcompView, quietly = TRUE)){
      suppressMessages(install.packages("multcompView"))
      }
if (!require(lmtest, quietly = TRUE)){
      suppressMessages(install.packages("lmtest"))
      }
if (!require(effectsize, quietly = TRUE)){
      suppressMessages(install.packages("effectsize"))
      }
```


```{r, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
# Statistical package 
library(stats)
# Ggplot2 package
library(ggplot2)
# Plotly package
library(plotly)
# Reshape2 package  
library(reshape2)
# GGally package
library(GGally)
# Tidyr package
library(tidyr)
# Lsr package
library(lsr)
# Car package
library(car)
# Pwr package
library(pwr)
# Tukey package
library(multcompView)
# Durbin Watson Test package
library(lmtest)
# Effect Size for ANOVA
library(effectsize)
# UFT-8 Encoding
options(Encoding="UTF-8")
```

\renewcommand{\figurename}{Figura}
\renewcommand{\tablename}{Tabela}

# Introdução

O mercado de ações é uma forma de investimento onde uma das maneiras de se obter lucratividade é vender as ações quando seus preços atuais estiverem acima do preço no qual foram adquiridas \cite{toro}. Embora a rentabilidade passada não seja garantia de rentabilidade futura, normalmente o histórico de rentabilidade é um fator a ser considerado \cite{bb}.

Neste estudo de caso deseja-se verificar, qual ação dentre cinco candidatas possui maior potencial de **ganho mensal** ao investidor quando escolhida com exclusividade, isto é, quando o montante é investido por completo em uma única ação. Para isso, considera-se o fechamento das cinco ações nos últimos 36 meses.

# Planejamento dos Experimentos

Dado que o investidor deseja a maior rentabilidade mensal possível, a série temporal dos preços de fechamento das ações foram utilizadas para calcular a taxa de retorno das cinco ações em cada um dos meses. Tal índice permite avaliar o lucro de uma ação durante um mês, expresso como uma proporção do investimento no mês anterior. A taxa de retorno de uma ação $i$ em um determinado mês $j$ é dada por \eqref{eq:ror}:

\begin{equation}
\label{eq:ror}
r_j^i = \frac{p^i_j - p^i_{j-1}}{p^i_{j-1}}
\end{equation}
onde $p^i_j$ é o preço de fechamento da ação $i$ no mês atual $j$ e $p^i_{j-1}$ é o preço de fechamento da ação $i$ no mês anterior $j-1$.

Quando o preço de fechamento da ação no mês corrente é superior ao preço de fechamento da ação no mês anterior ($p^i_j > p^i_{j-1}$), o retorno expressará o ganho líquido obtido do mês $j-1$ para o mês $j$. Em contrapartida, se o preço de fechamento da ação no mês corrente é inferior ao preço de fechamento da ação no mês anterior ($p^i_j < p^i_{j-1}$), o retorno expressará a perda líquida obtida nessa mesma transição mensal. Uma vez que o presente cálculo considera diferenças entre cotações adjacentes, o tamanho amostral é reduzido em uma unidade ($n = 35$).

As hipóteses estatísticas foram definidas com objetivo de verificar as seguintes proposições:
\begin{itemize}
\item Dentre o grupo de ações candidatas, qual delas possui maior potencial de rentabilidade mensal para o investidor?
\item Caso haja mais de uma ação em destaque, quais são elas e qual deveria ser escolhida entre elas?
\end{itemize}

Considerando as questões propostas, foram estabelecidas as hipóteses de teste sobre o retorno médio mensal das ações:
$$
  \begin{cases} 
      H_0: \mu_{A_{1}} = \mu_{A_{2}} =  \mu_{A_{3}} =  \mu_{A_{4}} =  \mu_{A_{5}} &\\H_1: \text{duas ou mais médias são diferentes das demais}
  \end{cases}
$$
onde a hipótese nula $H_0$ implica na igualdade entre os retornos médios mensais das cinco ações ao nível de confiança $1-\alpha$ e a hipótese alternativa bilateral $H_1$ na diferença entre duas ou mais ações em relação ao retorno médio mensal também ao nível de confiança $1-\alpha$.

Os parâmetros experimentais considerados para realização dos testes são nível de significância $\alpha = 0,05$ e potência desejada do teste $\pi^{*} = 1-\beta = 0,80$.

# Análise Exploratória de Dados

Algumas primeiras propriedades amostrais referentes ao retorno mensal das cinco ações, como média, moda, mediana, valores extremos, variância e desvio podem ser obtidas de imediato. A fim de facilitar a interpretabilidade dessas estatísticas amostrais, os retornos médios mensais são apresentados em porcentagem, ou seja, os valores originais obtidos pela Equação \eqref{eq:ror} foram multiplicados por 100. 

```{r, results = 'hide', echo = FALSE}
# Carrega 5 ações com 36 observações cada
sample <- read.csv('DadosAcoesGrupoD.csv', sep = ',', header = FALSE, col.names = c('A1','A2','A3','A4','A5'))

# Tratamento de vírgula como separador decimal
sample$A1 <- as.numeric(sub(pattern = ',', replacement = '.', sample$A1))
sample$A2 <- as.numeric(sub(pattern = ',', replacement = '.', sample$A2))
sample$A3 <- as.numeric(sub(pattern = ',', replacement = '.', sample$A3))
sample$A4 <- as.numeric(sub(pattern = ',', replacement = '.', sample$A4))
sample$A5 <- as.numeric(sub(pattern = ',', replacement = '.', sample$A5))
```

```{r, echo = FALSE}
# Cálculo do Retorno Mensal (loop)
rate_of_return_loop <- matrix(0, nrow = nrow(sample)-1, ncol = ncol(sample))
for (j in 1:ncol(sample)) {
  for (i in 1:((nrow(sample)-1))){
    rate_of_return_loop[i,j] = (sample[i,j] - sample[i+1,j])/(sample[i+1,j])
  }
}
```

```{r, echo = FALSE}
# Cálculo do Retorno Mensal (matricial)
differences <- diff(as.matrix(sample))
rate_of_return_matrix <- -differences/sample[2:36,]
```

```{r, echo = FALSE}
# Se os cálculos matriciais e por loop coincidirem em todas as posições, atualiza a minha amostra
if (all(rate_of_return_loop == rate_of_return_matrix) == TRUE){
  sample <- rate_of_return_matrix
}
```

```{r, results = 'hide', echo = FALSE}
# Função que calcula a moda
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r, results = 'hide', echo = FALSE}
# Estatísticas iniciais da ação 1
stats_A1 <- data.frame('Variância' = var(sample$A1), 'Média' = mean(sample$A1), 'Moda' = getmode(sample$A1), 'Mediana' = median(sample$A1), 'Mínimo' = min(sample$A1), 'Máximo' = max(sample$A1), 'Desvio' = sd(sample$A1))

# Estatísticas iniciais da ação 2
stats_A2 <- data.frame('Variância' = var(sample$A2), 'Média' = mean(sample$A2), 'Moda' = getmode(sample$A2), 'Mediana' = median(sample$A2), 'Mínimo' = min(sample$A2), 'Máximo' = max(sample$A2), 'Desvio' = sd(sample$A2))

# Estatísticas iniciais da ação 3
stats_A3 <- data.frame('Variância' = var(na.omit(sample$A3)), 'Média' = mean(na.omit(sample$A3)), 'Moda'  = getmode(na.omit(sample$A3)), 'Mediana' = median(na.omit(sample$A3)), 'Mínimo' = min(na.omit(sample$A3)), 'Máximo' = max(na.omit(sample$A3)), 'Desvio' = sd(na.omit(sample$A3)))

# Estatísticas iniciais da ação 4
stats_A4 <- data.frame('Variância' = var(na.omit(sample$A4)), 'Média' = mean(na.omit(sample$A4)), 'Moda'  = getmode(na.omit(sample$A4)), 'Mediana' = median(na.omit(sample$A4)), 'Mínimo' = min(na.omit(sample$A4)), 'Máximo' = max(na.omit(sample$A4)), 'Desvio' = sd(na.omit(sample$A4)))

# Estatísticas iniciais da ação 5
stats_A5 <- data.frame('Variância' = var(na.omit(sample$A5)), 'Média' = mean(na.omit(sample$A5)), 'Moda'  = getmode(na.omit(sample$A5)), 'Mediana' = median(na.omit(sample$A5)), 'Mínimo' = min(na.omit(sample$A5)), 'Máximo' = max(na.omit(sample$A5)), 'Desvio' = sd(na.omit(sample$A5)))
```

```{r, echo = FALSE}
stats <- data.frame(rbind(stats_A1, stats_A2, stats_A3, stats_A4, stats_A5),
                    row.names = c("A1", "A2", "A3", "A4", "A5"))
show(stats*100)
```

```{r, results = 'hide', echo = FALSE}

# Meses que ocorreram os extremos, lembrando que as linhas de menor índice se referem aos meses mais atuais
cat('Máximos\n')
cat('Mês:', 36 - which.max(sample$A1), 'Retorno:', max(sample$A1)*100, '\n')
cat('Mês:',36 - which.max(sample$A2), 'Retorno:', max(sample$A2)*100, '\n')
cat('Mês:',36 - which.max(sample$A3), 'Retorno:', max(sample$A3)*100, '\n')
cat('Mês:',36 - which.max(sample$A4), 'Retorno:', max(sample$A4)*100, '\n')
cat('Mês:',36 - which.max(sample$A5), 'Retorno:', max(sample$A5)*100, '\n')
cat('Mínimos\n')
cat('Mês:',36 - which.min(sample$A1), 'Retorno:', min(sample$A1)*100, '\n')
cat('Mês:',36 - which.min(sample$A2), 'Retorno:', min(sample$A2)*100, '\n')
cat('Mês:',36 - which.min(sample$A3), 'Retorno:', min(sample$A3)*100, '\n')
cat('Mês:',36 - which.min(sample$A4), 'Retorno:', min(sample$A4)*100, '\n')
cat('Mês:',36 - which.min(sample$A5), 'Retorno:', min(sample$A5)*100, '\n')

```

A princípio, é possível observar que, durante os últimos 3 anos, os retornos mensais de duas dentre as cinco ações candidatas apresentaram, em média, retorno negativo, são elas $A_1$ e $A_3$. No entanto, é interessante ressaltar que todas as ações tiveram retornos mensais negativos em algum momento da série histórica. O maior retorno negativo constatado foi o da ação $A_3$ com uma perda de $-3,79\%$ no 20º mês e o menor retorno negativo foi $-0,26\%$ da ação $A_4$ no 17º mês. A ação $A_4$ obteve o maior ganho líquido médio, cerca de $1,20\%$ e a ação $A_2$ apresentou o maior retorno máximo mensal, $4,24\%$ no 16º mês. O pior rendimento máximo foi de $1,85\%$ pela ação $A_3$ no 9º mês.

Um fator interessante é que as diferenças absolutas entre os retornos amostrais mensais médios e os retornos amostrais mensais medianos de todas as ações foram bem próximas de zero, isto é, $\Delta_i = |\overline{\mu_i} - \overline{m_i}| \approx 0$ para $i \in \{1,5\}$. A maior diferença obtida, por exemplo, foi de $0,14\%$ para a ação $A_3$. Apesar de ser uma suposição fracamente sustentada, isso sugere que as distribuições de probabilidade amostrais podem ser aproximadas, a priori, por uma distribuição normal. No que se refere às variâncias amostrais das ações, percebe-se que os valores são bastante similares e aproximadamente iguais a $0,01\%$, o que também sugere que as amostras são homocedásticas.

Com o intuito de compreender melhor os dados em estudo e, posteriormente, inferir sobre as populações de onde as amostras provêm, serão analisadas algumas representações gráficas. No que tange a distribuição de frequência das observações, com exceção da ação $A_4$, todas as demais ações apresentam curvas em formato de sino, o que fortalece o pressuposto de normalidade mencionado anteriormente. 

```{r, results = 'hide', echo = FALSE}
As <- melt(sample, id.vars = NULL)
```

```{r histogram, echo = FALSE, fig.height = 2.8, fig.width = 6, fig.align = 'center', fig.cap = 'Histogramas.', fig.pos = 'H'}
# Histogramas
ggplot(As, aes(value)) + xlab("Retorno Mensal") + 
    ylab("Frequência") + geom_histogram(bins = 20) + 
    facet_wrap(~variable, scales = 'free')
```

\noindent Ainda a partir dos histogramas, pode-se evidenciar que durante os 36 meses coletados, as ações $A_1$ e $A_3$ tiveram a maioria dos rendimentos mensais no domínio negativo (perda líquida) e as ações $A_2$, $A_4$ e $A_5$ apresentaram a maioria dos rendimentos mensais no domínio positivo (ganho líquido). 

Segundo os diagramas de caixa, apenas a distribuição de retornos mensais da amostra $A_1$ é visualmente simétrica e, portanto apresenta evidências de normalidade. No caso das demais ações, as medianas não estão tão próximas da média, uma vez que os segundos quartis estão deslocados dos respectivos centros das caixas. Essa dubiedade de interpretações entre os histogramas e os *boxplots* acerca da normalidade dos dados instiga análises mais aprofundadas, como serão realizadas a seguir. Além dessas verificações, outra circunstância notável é a presença de *outliers* apenas nas distribuições amostrais das ações $A_2$ e $A_3$.

```{r boxplot, echo = FALSE, fig.height = 2.8, fig.width = 6, fig.align = 'center', fig.cap = 'Boxplots.', fig.pos = 'H'}
# Boxplots
ggplot(data = As, aes(y = "", x = value)) + xlab("Retorno Mensal") + 
    ylab("") + geom_boxplot(lwd = 0.3) + 
    facet_wrap(~variable, scales = 'free') + coord_flip()
```

Outra possibilidade para examinar a normalidade é considerar gráficos quantil-quantil. Essa representação permite comparar as distribuições de probabilidade de cada uma das ações (eixo das ordenadas) com uma distribuição normal (eixo das abcissas). Mediante a boa qualidade do ajuste da reta nos pontos para todas as ações, pode-se concluir que há fortes indícios de que os resíduos das distribuições são normais.

```{r qqplot, echo = FALSE, fig.height = 2.8, fig.width = 6, fig.align = 'center', fig.cap = 'QQ-Plots.', fig.pos = 'H'}
# QQ-Plots
ggplot(data = As, aes(sample = value)) +
  facet_wrap(~variable, scales = "free") +
  stat_qq() + stat_qq_line() + scale_y_continuous(name = 'Quantis da Amostra') + 
  scale_x_continuous(name = 'Quantis Teóricos Normais')
```

# Validação de Premissas

A premissa de normalidade será validada pelo teste não-paramétrico de Shapiro-Wilk. A hipótese nula desse teste afirma que a amostra proveio de uma população com distribuição normal e a hipótese alternativa é de que a amostra não proveio de uma distribuição normal \cite{ShapiroWilkTest}. O nível de significância utilizado para cada teste foi de $\alpha = 0,10$.

```{r, echo = FALSE}
# Testes de Normalidade
show(rbind(shapiro.test(sample$A1), shapiro.test(sample$A2), shapiro.test(sample$A3), shapiro.test(sample$A4), shapiro.test(sample$A5)))
```

Não foi possível rejeitar a hipótese nula em nenhum dos casos, visto que os p-valores obtidos são maiores que o nível de significância pré-estabelecido ($p > \alpha$). Assim, pode-se afirmar ao nível de confiança de $90\%$ que as amostras de todas as ações provêm de populações com distribuição normal. Como a premissa de normalidade foi validada, não é necessário evocar o Teorema Central do Limite (TCL), que ainda assim seria viável devido o tamanho amostral ser suficiente $(n = 35) > 30$.

Alguns testes estatísticos de múltiplas amostras, cujas hipóteses nulas são construídas a partir do parâmetro média amostral, são altamente sensíveis a premissa de independência das amostras, como é o caso do ANOVA. Embora não exista um procedimento específico para testar a independência das amostras no caso geral, o caso especial de autocorrelações em série nos dados pode ser testado pelo Teste de Durbin-Watson \cite{Campelo2018-LNDoE}. A hipótese nula desse teste declara que não há correlação entre os resíduos, isto é, os resíduos são independentes. A hipótese alternativa, por sua vez, afirma que os resíduos são correlacionados \cite{DurbinWatsonTest}. Assim, a correlação entre os resíduos foi tomada segundo a abordagem de todos contra todos, cujo intuito é avaliar as correlações entre todas as 10 possíveis combinações das ações par a par ($A_1 \times A_2$, $A_1 \times A_3$, $A_1 \times A_4$, $A_1 \times A_5$, $A_2 \times A_3$, $A_2 \times A_4$, $A_2 \times A_5$, $A_3 \times A_4$, $A_3 \times A_5$ e $A_4 \times A_5$). O nível de significância utilizado para esse teste foi $\alpha = 0,05$.

```{r, echo = FALSE}
# Teste de independência dos resíduos (todos contra todos)
durbin_watson_tests <- data.frame(rbind(dwtest(sample$A1 ~ sample$A2), dwtest(sample$A1 ~ sample$A3), dwtest(sample$A1 ~ sample$A4), dwtest(sample$A1 ~ sample$A5), dwtest(sample$A2 ~ sample$A3), dwtest(sample$A2 ~ sample$A4), dwtest(sample$A2 ~ sample$A5), dwtest(sample$A3 ~ sample$A4), dwtest(sample$A3 ~ sample$A5), dwtest(sample$A4 ~ sample$A5)))

show(durbin_watson_tests[c('data.name', 'method', 'p.value', 'statistic')])
```

Não é possível rejeitar a hipótese nula ao nível de confiança estabelecido para nenhuma das combinações par a par das ações, uma vez que os p-valores foram todos superiores ao nível de significância. Assim, pode-se afirmar que os resíduos amostrais entre todos os pares de ações são independentes ao nível de confiança de $95\%$.

Com a finalidade de avaliar a premissa de homocedasticidade, o teste paramétrico de Bartlett foi empregado. Esse teste permite comparar as variâncias de três ou mais grupos e possui como premissa tanto a independência quanto a normalidade das amostras, que foram anteriormente validadas. A hipótese nula desse teste afirma que as variâncias de todas as populações das quais vieram as amostras são iguais e a hipótese alternativa afirma que há pelo menos uma diferença entre as variâncias dessas populações \cite{BartlettTest}. O nível de significância foi definido em $\alpha = 0,05$.

```{r, echo = FALSE}
# Teste de Homocedasticidade
bartlett.test(x = sample)
```
A partir do p-valor substancialmente maior que o nível de significância ($0,7798 >\!\!> 0,05$), não se pode refutar a hipótese nula e, portanto, ao nível de confiança de $95\%$, tem-se que as variâncias populacionais de todas as ações são iguais.

# Análise Estatística


Para prosseguimento do estudo a respeito dos rendimentos das ações, foi proposto a comparação de médias utilizando-se o Anova. Apesar de ser considerado robusto às violações moderadas da normalidade e homoscedasticidade \cite{carrano}, foram provados através dos testes anteriores que as amostras preenchem esses requisitos. Quanto à independência, a ANOVA é sensível a essa violação, no entanto, essa premissa também foi testada e validada. Assim, pode-se utilizar esse teste para comparação das médias.

O teste proposto, também conhecido como *One Way*, tem como hipótese nula que as médias dos grupos em análise é a mesma, e como hipótese alternativa de pelo menos duas ou mais médias se distingue das demais.  Dessa forma, este método verifica se as diferenças observadas na média são grandes o suficiente para ser o resultado da seleção aleatória, e pra isso além de considerar a diferença absoluta entre as amostras, também é considerado a variabilidade dentro de cada tratamento. Assim, verifica-se se a diferença entre os tratamentos é muito maior que a diferença no tratamento, e isso é possível fazendo a comparação da variância entre os grupos com a variância dentro do próprio grupo, o que dá nome ao teste \cite{stan}. A seguir, é possível ver o resultado do emprego deste teste, por meio da função aov() do pacote *stats* do R \cite{aov}. 


```{r, echo = FALSE, fig.height = 4, fig.width = 6, fig.align = 'center'}
# ANOVA
grupos <- data.frame(cbind(sample[,1], sample[,2], sample[,3], sample[,4], sample[,5]))
grupos <- stack(grupos)
anova <- aov(values ~ind, data=grupos)
summary(anova)


```
No experimento em questão, o p valor retornado foi $p = 2 \times 10^{-16}$, o que significa que com 95% de confiança, a hipótese nula de que as médias dos rendimentos são iguais, é rejeitada. Ou seja, foram detectadas diferenças significativas entre as medias dos rendimentos das ações em estudo.

Além do valor p, também é retornado $F = 34.17$, que é calculado a partir do quociente do quadrado médio entre os tratamentos ($0,003966$) pelo quadrado dos resíduos ($0,000116$). Nota-se que o numerador desta operação é muito maior que o denominador, que consequentemente resulta em um $F$ grande. Nesse sentido, quanto maior essa proporção, maior a confiança em rejeitar a hipótese nula.
 
Todavia, embora o Anova seja capaz de identificar a existência dessa distinção entre médias, quando a hipótese nula é rejeita, é preciso identificar quais foram diferenças significativas, que não é uma das atribuições deste método. Para isso são utilizados ferramentas de comparações múltiplas ou ferramentas de correções de significância.

Para encontrar quais ações tem média de rendimento significantemente diferente será aplicado o teste de Tukey, uma ferramenta de comparações múltiplas. Este executa comparações do tipo todos com todos e demonstra ser interessante para este propósito, pois além de ser de fácil aplicação, é considerado um método poderoso. Em grupos amostrais balanceado ele é um teste exato, ou seja, a taxa de erro do grupo testado é exatamente o parâmetro $\alpha$. Isso constitui uma grande vantagem do método, pois esse tipo de precisão é considerado raro dentre os testes para essa finalidade \cite{oper}.


```{r, echo = FALSE, fig.height = 4, fig.width = 6, fig.align = 'center'}
# TURKEY
TUKEY <- TukeyHSD(x = anova, conf.level = 0.95)
TUKEY
plot(TUKEY , las = 1 , col = "blue")

```
Os dados extraídos do teste de Tukey são apresentados graficamente. Baseado no intervalo de confiança das diferenças das médias dos rendimentos, verifica-se que as ações ($X3$ e $X1$) e ($X4$ e $X2$) não são significativamente diferentes, pois este dois intervalos contém o zero (0). Já os demais intervalos ($X2$ e $X1$), ($X4$ e $X1$), ($X5$ e $X1$), ($X3$ e $X2$), ($X5$ e $X2$), ($X4$ e $X3$), ($X5$ e $X3$) e ($X5$ e $X4$) têm rendimentos significativamente diferentes, como mostrado graficamente.

Pela analise do p valor, tem-se a mesma conclusão, visto que os intervalos dos rendimentos das ações ($X3$ e $X1$) e ($X4$ e $X2$) retornou p valor maior que $0,05$. Os demais p valores são menores que o nível de significância igual a $0,05$, enfatizando que têm rendimentos significativamente diferentes.

Nesse sentido, o teste Tukey deixa em evidência que as ações $X2$ e $X4$ foram as que obtiveram rendimentos médios melhores em detrimento das demais, e embora $X4$ tenha média levemente mais alta que $X2$, não trata-se de uma diferença significativa estatisticamente. Ressalta que o valor de p para a comparação realizada pelo teste de Tukey foi muito alto ($p = 0,98355$), que reforça que estatisticamente os rendimentos obtidos ao investir em qualquer uma das duas, na média, são iguais. Sendo assim, caso o rendimento passado venha ser usado nessa escolha, dentre os grupos de ações fornecidos, a análise estatística realizada não permite identificar uma melhor, dentre as duas em evidência  ($X2$ e $X3$).

## Dispersão de X2
```{r scatterplot_X2, echo = FALSE, fig.height = 2.8, fig.width = 6, fig.align = 'center', fig.pos = 'H'}
int_scatterplot <- 35:1
ggplot(data = sample, aes(x = int_scatterplot, y = sample[,2])) + 
          ggtitle("Rentabilidade nos ultimos 36 meses") +
          labs(x = "Mês de analise", y = "Rentabilidade da Ação X2")+
          geom_line()
```

## Dispersão de X4
```{r scatterplot_X4, echo = FALSE, fig.height = 2.8, fig.width = 6, fig.align = 'center', fig.pos = 'H'}
ggplot(data = sample, aes(x = int_scatterplot, y = sample[,4])) + 
          ggtitle("Rentabilidade nos ultimos 36 meses") +
          labs(x = "Mês de analise", y = "Rentabilidade da Ação X4")+
          geom_line()
```


Como critério para definição de qual ação deve-se invertir entre as duas, visto que estatisticamente elas oferecem mesmo rendimento, foi utilizado como critério de desempate aquela que oferece menos risco ao investimento. Entre os indicadores de risco foi selecionado o numero de vezes em que a rentabilidade das ações foi negativo e a tendencia da ação para os proximos meses.
Dessa forma, em comparação, a ação $X2$ com seis momentos de rentabilidade negativa, ou seja, que queda no valor da ação em relação a interação anterior. Já a ação $X4$ somente com três momentos onde houve queda no valor da ação em relação ao mês anterior. 
Já com relação a perpectiva para os proximos meses, o grafico de dispersção sugere que devido a queda na rentabilidade da ação $X4$ nos ultimos três meses, em oposto a ação $X2$, a ação $X4$ tende a voltar a subir para manter a média de investimento observada no estudo.

Por estes motivos, a ação com melhor desempenho e caracteristicas é a ação $X4$.

# Tamanho de Efeito

A fim de investigar o tamanho de efeito para as diferenças de médias de três grupos ou mais, diversas medidas foram desenvolvidas, entre elas *Eta-Squared* ($\eta^2$), *Partial Eta-Squared* ($\eta_p^2$), *Omega-Squared* ($\omega^2$) e *Epsilon-Squared* ($\epsilon^2$). Dada a preferência de uso na literatura pela *Eta-Squared*, essa será a medida utilizada para estimar o tamanho de efeito no presente experimento \cite{Yigit2018}. Além disso, para o ANOVA de uma única via (*One Way*), *Eta-Squared* é equivalente ao *Partial Eta-Squared* e é dado por \eqref{eq:eta-squared} \cite{Yigit2018}:

\begin{equation}
  \label{eq:eta-squared}
  \eta^2 = \frac{SS_{Effect}}{SS_{Total}}
\end{equation}
onde $SS_{Total}$ é igual a somas dos quadrados totais e $SS_{Effect}$ é a soma dos quadrados dos efeitos. O pacote `effectsize` do R permite calcular diretamente o $\eta^2$ a partir da tabela de resultados do ANOVA \cite{EffectSize}.

```{r, echo = FALSE}
# Cálculo do Tamanho de Efeito
effect_size <- eta_squared(anova)
show(effect_size)
```
A estimativa pontual obtida para o tamanho de efeito foi $\eta^2 = 0,45$. Ao nível de confiança de $90\%$, tem-se ainda que o intervalo de confiança bilateral do tamanho de efeito é $[0,35; \ 0,52]$. 

Uma das maneiras mais usuais de analisar o tamanho de efeito *Eta-Squared* é convertê-lo para a estimativa $f$ de Cohen, cujos valores são tabelados segundo interpretações qualitativas \cite{fCohenTable}:

\begin{multicols}{3}
  \begin{itemize}
    \item Pequeno: $f \leq 0,10$;
    \item Médio: $0,10 < f \leq 0,25$;
    \item Grande: $f \geq 0,25$.
  \end{itemize}
\end{multicols}

A relação entre $\eta^2$ e $f$ é dada pela Equação \eqref{eq:f_to_eta} \cite{Yigit2018}:

\begin{equation}
  \label{eq:f_to_eta}
  \eta^2 = \frac{f^2}{1+f^2}
\end{equation}

```{r, echo = FALSE, results = 'hide'}
# Cálculo do f de Cohen
f <- sqrt((effect_size$Eta_Sq_partial^2)/(1-effect_size$Eta_Sq_partial^2))
```

\noindent Como a relação inversa é necessária, basta manipular algebricamente a Equação \eqref{eq:f_to_eta}, de modo a obter a Equação \eqref{eq:eta_to_f}:

\begin{equation}
  \label{eq:eta_to_f}
  f = \sqrt{\frac{\eta^2}{1-\eta^2}} 
\end{equation}
\noindent Assim, tem-se uma estimativa pontual de tamanho de efeito grande e igual a $f = 0,4978$. Quanto ao intervalo de confiança bilateral ao nível de confiança de $90\%$, tem-se $f \in [0,3745; \ 0,5941]$. A relação entre os tamanhos de efeito das medidas $f$ e $\eta^2$ no intervalo de confiança pode ser visualizada na Figura 4.

```{r, echo = FALSE, results = 'hide'}
# Intervalo de confiança de f ao nível de confiança de 90%
etas <- seq(effect_size$CI_low, effect_size$CI_high, 0.01)
fs <- c()
for (i in 1:length(etas)) {
  fs[i] <- sqrt((etas[i]^2)/(1-etas[i]^2))
}
df <- data.frame(etas = etas, fs = fs)
```

```{r f_eta, echo = FALSE, fig.height = 2.2, fig.width = 3, fig.align = 'center', fig.cap = 'Relação entre o $f$ de Cohen e o $\\eta^2$ no intervalo de confiança.', fig.pos = 'H'}
ggplot(data = df, aes(x = etas, y = fs, group = 1)) +
  xlab((expression(eta^2))) + 
  ylab(expression(italic(f))) + 
  geom_line(linetype = 'dashed')+
  geom_point()
```

# Poder do Teste

Tendo em vista o número de grupos $k = 5$, o número de amostras em cada grupo $n = 35$, o nível de significância previamente estabelecido $\alpha = 0,05$ e o tamanho de efeito $f = 0,4978$, torna-se possível verificar se a potência desejada do teste foi alcançada. Para tal, foi utilizado o método `pwr.anova.test` do pacote `pwr` \cite{PowerAnovaTest}.

```{r, echo = FALSE}
# Cálculo da Potência
pwr.anova.test(k = ncol(sample), n = nrow(sample), sig.level = 0.05, f = f)
```

O poder do teste foi bastante alto para o experimento conduzido ($\pi = 0,9999$), sendo substancialmente superior ao valor desejado ($\pi^{*} = 0,80$). Obter exatamente a potência desejada implicaria em detectar ganhos maiores ou iguais a $f = 0,2648$, isto é, ter um tamanho de efeito mais próximo do que é considerado um tamanho de efeito médio.

```{r, echo = FALSE}
# Cálculo da Potência
pwr.anova.test(k = ncol(sample), n = nrow(sample), sig.level = 0.05, power = 0.8)

```

# Conclusões

A aplicação do Anova para comparação das médias dos rendimentos das ações, mostrou que havia distinção em pelo menos uma média, dentre o grupo avaliado. Com intuito de determinar onde essas diferenças se encontravam, foi realizado o teste de Tukey, que faz a comparação do tipo todos contra todos, e permite identificar, com base no valor de $p$, se as diferenças encontradas são estatisticamente significativas, ao nível de confiança de $95\%$. Nesse contexto, duas ações destacaram-se em relação às demais, $X2$ e $X4$, porém, não apresentaram diferenças significativas quando comparadas entre si. Haja vista que além das médias, as variâncias das suas amostras também é estatisticamente igual, somente com esses dados, não é possível inferir, estatisticamente, qual delas traria o maior retorno financeiro.
A fim de escolher dentre as duas que tem melhor rentabilidade, foi utilizado critérios que caracterizam o nivel de risco ao investir nessas ações. Após analise do risco, a ação $X4$ apresentou menor risco ao investimento perante a ação $X2$, tento como ação final para investimento no proximo mês.

## Discussão de Melhorias

Quando se trata de investimentos em ações, alguns indicadores são sujeridos pelo mercado. No estudo em questão, após analise dos rendimentos, foi observado duas ações em destaque. Como sugestão para definição da mais indicada entre as duas, foi proposto o Indice Preço sobre Lucro (P/L), porém para cálculo deste indicador, entre outros parâmetros, é necessario conhecer o número de papéis que a empresa detentora destas ações disponibilizaram ao mercado.

## Atividades Desempenhadas

A hipótese de teste foi definida em concordância com os três autores, bem como a definição de conversão dos preços de fechamento mensais em taxas de retorno mensais para melhor condução do experimento. O pré-processamento dos dados, a análise exploratória e a validação das premissas foram conduzidas pelo Pedro. A análise estatística, por sua vez, que inclui tanto a verificação da existência de diferenças entre as médias das cinco ações quanto o teste de comparações múltiplas a posteriori, foi realizada pelo Savio e pela Samara. A estimativa do tamanho de efeito e o cálculo do poder de teste foram elaborados pelo Pedro. Por fim, a Samara e o Savio concluiram o trabalho com as considerações finais e discussões de melhoria.

\renewcommand\refname{Referências}
\bibliographystyle{plain}
\bibliography{ref}