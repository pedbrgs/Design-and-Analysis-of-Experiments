---
title: |
    | Planejamento e Análise de Experimentos (EEE933)
    | Estudo de Caso 2
#title: Planejamento e Análise de Experimentos (EEE933) Estudo de Caso 1
author: Pedro Vinícius, Samara Silva e Savio Vieira
date: 24 de Agosto de 2020
output:
  pdf_document:
    #latex_engine: xelatex
    fig_caption: yes
  html_document:
    df_print: paged
indent: true
header-includes: 
    - \usepackage{indentfirst}
    - \usepackage{float}
    - \usepackage{multicol}
bibliography: ref.bib
doi: https://github.com/pedbrgs/Design-and-Analysis-of-Experiments
pagetitle: Estudo de Caso 2
---

```{r setup, results='hide', warning=FALSE, include = FALSE, message = FALSE, echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away. 
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
}
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(stats, quietly = TRUE)){
      suppressMessages(install.packages("stats"))
      }
if (!require(plotly, quietly = TRUE)){
      suppressMessages(install.packages("plotly"))
      }
if (!require(reshape2, quietly = TRUE)){
      suppressMessages(install.packages("reshape2"))
      }
if (!require(tidyr, quietly = TRUE)){
      suppressMessages(install.packages("tidyr"))
}
if (!require(effsize, quietly = TRUE)){
      suppressMessages(install.packages("effsize"))
      }
if (!require(pwr, quietly = TRUE)){
      suppressMessages(install.packages("pwr"))
      }
if (!require(lsr, quietly = TRUE)){
      suppressMessages(install.packages("lsr"))
      }
```


```{r, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
# Statistical package 
library(stats)
# Ggplot2 package
library(ggplot2)
# Plotly package
library(plotly)
# Reshape2 package  
library(reshape2)
# GGally package
library(GGally)
# Tidyr package
library(tidyr)
# Effect size package
library(effsize)
# Lsr package
library(lsr)
# Car package
library(car)
# Pwr package
library(pwr)
# UFT-8 Encoding
options(Encoding="UTF-8")
```

\renewcommand{\figurename}{Figura}
\renewcommand{\tablename}{Tabela}

# Introdução

\par O Índice de Massa Corporal (IMC) é uma medida de gordura corporal baseada na relação entre peso (em $kg$) e altura (em $m$) de um indivíduo e é comumente utilizado como uma ferramenta de triagem para indicar se uma pessoa está com um peso saudável para sua altura. Este índice é calculado conforme a Equação \ref{eq:imc}:

\begin{equation}
  \label{eq:imc}
  IMC = \frac{peso}{(altura)^2} 
\end{equation}

\noindent em $kg/m^2$. Cada faixa de IMC permite classificar o indivíduo em uma das seguintes categorias \cite{Alexandra2007}:

\begin{multicols}{3}
  \begin{itemize}
    \item Baixo peso: $< 18,5$
    \item Peso normal: $18,5 - 25$
    \item Sobrepeso: $25 - 30$
    \item Obesidade: $30 - 35$
    \item Obesidade mórbida: $> 40$
  \end{itemize}
\end{multicols}

Neste estudo de caso deseja-se comparar o IMC médio dos alunos de Pós-Graduação em Engenharia Elétrica (PPGEE) da Universidade Federal de Minas Gerais (UFMG) de dois semestres distintos: $2016/2$ e $2017/2$. Para tal fim, foram disponibilizadas duas amostras, contendo sexo, altura e peso de alguns alunos \cite{Campelo2018-LNDoE}. Assim, duas análises estatísticas independentes são propostas: (i) uma sobre o IMC médio dos alunos do sexo masculino e (ii) uma sobre o IMC médio dos alunos do sexo feminino. Para ambos os casos, a condução dos experimentos foram similares, no entanto, alguns testes estatísticos tiveram que ser adaptados de acordo com as propriedades das distribuições amostrais em investigação, que foram validadas previamente.

# Planejamento dos Experimentos

As hipóteses estatísticas foram definidas com o intuito de responder às questões propostas abaixo:

* Há evidências de que o IMC médio dos alunos do PPGEE/UFMG de $2016/2$ é diferente do IMC médio dos alunos do PPGEE/UFMG de $2017/2$ no que se refere ao sexo masculino?
* Há evidências de que a mediana do IMC dos alunos do PPGEE/UFMG de $2016/2$ é diferente da mediana do IMC dos alunos do PPGEE/UFMG de $2017/2$ no que se refere ao sexo feminino?

Em concordância com a proposta de comparação do IMC médio entre os alunos de semestres distintos e o IMC mediano entre as alunas de semestre distintos, as hipóteses de teste podem ser formuladas sobre o parâmetro média e mediana, respectivamente:

$$
  \begin{cases} 
      H_0: \mu_{M2016} = \mu_{M2017} &\\H_1: \mu_{M2016} \neq \mu_{M2017} 
  \end{cases}
  \begin{cases} 
      H_0: m_{F2016} = m_{F2017} &\\H_1: m_{F2016} \neq m_{F2017} 
  \end{cases}
$$

\noindent onde a hipótese nula $H_0$ implica na igualdade entre os IMCs médios ou medianos dos alunos de $2016/2$ e $2017/2$ e a hipótese alternativa bilateral $H_1$ na diferença dos IMCs médios ou medianos e, portanto, em uma potencial diferença dos estilos de vida dos alunos.

Os parâmetros experimentais para realização dos testes são:

* A probabilidade admissível de rejeição da hipótese nula quando ela é verdadeira é de apenas $5\%$, isto é, o nível de significância do teste é $\alpha = 0,05$;
* A potência do teste é de $\pi = 1 - \beta = 0,8$. Em outras palavras, deseja-se uma probabilidade de falha ao rejeitar a hipótese nula quando ela é falsa de $20\%$.

<!-- 
* O tamanho de efeito de mínima relevância prática será definito posteriormente na Subseção Tamanho de Efeito.
-->

## Pré-Processamento dos Dados

Conforme mencionado anteriormente, as bases de dados [imc_20162.csv](https://raw.githubusercontent.com/fcampelo/Design-and-Analysis-of-Experiments/master/data%20files/imc_20162.csv) e [CS01_20172.csv](https://raw.githubusercontent.com/fcampelo/Design-and-Analysis-of-Experiments/master/data%20files/CS01_20172.csv) foram disponibilizadas \cite{Campelo2018-LNDoE}. A amostra relativa ao semestre de $2016/2$ dispõe dos atributos número de identificação do aluno, visto que a coleta manteve o sigilo dos estudantes, curso (graduação ou pós-graduação), gênero, peso (em $kg$) e altura (em $m$). A princípio, foi necessário extrair apenas as informações dos alunos cujo vínculo com a universidade era de discente da pós-graduação e, posteriormente, realizar a fragmentação por gênero, formando duas amostras independentes ($M2016$ e $F2016$). A amostra relativa ao semestre de $2017/2$, por sua vez, compreendia os atributos peso (em $kg$), altura (em $m$), sexo e idade. Além disso, as observações eram somente de alunos da pós-graduação e, portanto, exigiu apenas a separação por gênero em duas outras amostras ($M2017$ e $F2017$).

A partir dos pesos e alturas disponíveis, os índices de massa corporal foram calculados para cada aluno, conforme a Equação \ref{eq:imc}. Por fim, as observações de interesse foram compiladas em uma única estrutura de dados. Os 8 primeiros IMCs de cada amostra podem ser visualizados abaixo, onde os valores "NA" presentes nas amostras femininas ($F2016$ e $F2017$) indicam que ambas possuem tamanho amostral $N < 8$, isto é, 7 e 4 observações, respectivamente. As amostras masculinas ($M2016$ e $M2017$), no entanto, apresentam 21 observações cada uma.

```{r, results = 'hide', echo = FALSE}
# Carrega dados relativos ao semestre de 2016/2
data2016 <- read.csv('imc_20162.csv')
# Seleciona apenas alunos do programa de pós-graduação
ppgee2016 <- data2016[data2016['Course'] == 'PPGEE',]
# Separa amostras por sexo
female2016 <- ppgee2016[ppgee2016['Gender'] == 'F',]
male2016 <- ppgee2016[ppgee2016['Gender'] == 'M',]
```

```{r, results = 'hide', echo = FALSE}
# Carrega dados relativos ao semestre de 2017/2
data2017 <- read.csv('CS01_20172.csv', sep = ';')
# Separa amostras por sexo
female2017 <- data2017[data2017['Sex'] == 'F',]
male2017 <- data2017[data2017['Sex'] == 'M',]
```

```{r, results = 'hide', echo = FALSE}
# Cálculo do Índice de Massa Corporal (IMC)

# Alunos de 2016/2
female2016['IMC.kg/m2'] <- female2016['Weight.kg']/(female2016['Height.m']^2)
male2016['IMC.kg/m2'] <- male2016['Weight.kg']/(male2016['Height.m']^2)

# Alunos de 2017/2
female2017['IMC.kg/m2'] <- female2017['Weight.kg']/(female2017['height.m']^2)
male2017['IMC.kg/m2'] <- male2017['Weight.kg']/(male2017['height.m']^2)
```

```{r, results = 'hide', echo = FALSE}

# Amostras de 2016/2
F2016 <- female2016$`IMC.kg/m2`
M2016 <- male2016$`IMC.kg/m2`

# Amostras de 2017/2
F2017 <- female2017$`IMC.kg/m2`
M2017 <- male2017$`IMC.kg/m2`
```

```{r, results = 'hide', echo = FALSE}
n_max <- max(length(F2016), length(F2017), length(M2016), length(M2017))
length(F2016) <- n_max
length(F2017) <- n_max
length(M2016) <- n_max
length(M2017) <- n_max

IMCs <- data.frame('M2016' = M2016, 'M2017' = M2017, 'F2016' = F2016, 'F2017' = F2017)
```

```{r, echo = FALSE, fig.align = 'center', fig.pos = 'H'}
# 10 primeiras observações de cada amostra
show(IMCs[c(1:8),])
```

## Análise Exploratória de Dados

```{r, results = 'hide', echo = FALSE}
# Função que calcula a moda
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r, results = 'hide', echo = FALSE}
# Estatísticas iniciais da amostra masculina de 2016
stats_M2016 <- data.frame('Variância' = var(M2016), 'Média' = mean(M2016), 'Moda' = getmode(M2016),
                                'Mediana' = median(M2016), 'Mínimo' = min(M2016), 
                                'Máximo' = max(M2016), 'Desvio' = sd(M2016))

# Estatísticas iniciais da amostra masculina de 2017
stats_M2017 <- data.frame('Variância' = var(M2017), 'Média' = mean(M2017), 'Moda' = getmode(M2017),
                                'Mediana' = median(M2017), 'Mínimo' = min(M2017), 
                                'Máximo' = max(M2017), 'Desvio' = sd(M2017))

# Estatísticas iniciais da amostra feminina de 2016
stats_F2016 <- data.frame('Variância' = var(na.omit(F2016)), 'Média' = mean(na.omit(F2016)), 
          'Moda'  = getmode(na.omit(F2016)), 'Mediana' = median(na.omit(F2016)), 
          'Mínimo' = min(na.omit(F2016)), 'Máximo' = max(na.omit(F2016)), 
          'Desvio' = sd(na.omit(F2016)))

# Estatísticas iniciais da amostra feminina de 2017
stats_F2017 <- data.frame('Variância' = var(na.omit(F2017)), 'Média' = mean(na.omit(F2017)), 
          'Moda'  = getmode(na.omit(F2017)), 'Mediana' = median(na.omit(F2017)), 
          'Mínimo' = min(na.omit(F2017)), 'Máximo' = max(na.omit(F2017)), 
          'Desvio' = sd(na.omit(F2017)))
```

Algumas primeiras propriedades das quatro amostras, como média, moda, mediana, valores extremos, variância e desvio podem ser obtidas de imediato.

```{r, echo = FALSE}
stats <- data.frame(rbind(stats_M2016, stats_M2017, stats_F2016, stats_F2017),
                    row.names = c("M2016", "M2017", "F2016", "F2017"))
stats
```

A priori, é possível evidenciar que a diferença entre as médias amostrais masculinas ($\Delta \bar{x}_{M} = 0,6504$) é bem menos discrepante que a diferença entre as médias amostrais femininas ($\Delta \bar{x}_{F} = 2,6378$). No que se refere a diferença entre as variâncias amostrais, tanto a disparidade do gênero masculino quanto do gênero feminino são bastante expressivas, sendo $\Delta s_{M} = 6,8904$ e $\Delta s_{F} = 3,2657$, respectivamente. Outro fato interessante é que as observações coletadas retratam que, na média, os alunos entrevistados de ambos os sexos seguem um padrão de vida ideal ($\overline{IMC} \in \ [18,5; \ 25]$), onde os homens estão mais próximos do limite superior (sobrepeso) e as mulheres estão mais próximas do limite inferior (baixo peso).

A fim de compreender melhor os dados em estudo e, posteriormente, inferir sobre as populações de onde as amostras provêm, serão analisadas algumas representações gráficas. No que tange a distribuição de frequência das observações, pode-se constatar que as amostras masculinas apresentam um comportamento bastante similar ao de uma distribuição normal. No caso da amostra $M2016$, em específico, tal característica seria melhor assimilada caso não houvesse o *outlier* cujo IMC é $37.55\ kg/m^2$. Em relação às amostras femininas, não é possível identificar indícios de normalidade a partir de seus histogramas, uma vez que os seus respectivos tamanhos amostrais são muito pequenos.

```{r, results = 'hide', echo = FALSE}
IMCs <- melt(IMCs, id.vars = NULL)
IMCs <- na.omit(IMCs)
```

```{r histogram, echo = FALSE, fig.height = 2.8, fig.width = 4, fig.align = 'center', fig.cap = 'Histogramas.', fig.pos = 'H'}
# Histogramas
ggplot(IMCs, aes(value)) + xlab(expression("IMC (kg/"*"m"^2*")")) + 
    ylab("Frequência") + geom_histogram(bins = 20) + 
    facet_wrap(~variable, scales = 'free')
```

Os diagramas de caixa, em princípio, corroboram algumas análises anteriores quanto às distribuições amostrais. O segundo quartil de $M2016$, em particular, está praticamente no centro da caixa, representando uma mediana próxima da média e, portanto, evidências de normalidade. O mesmo não ocorre para a amostra $M2017$, que visualmente apresenta maior assimetria do segundo quartil em relação ao centro da caixa. No entanto, a diferença entre a média e a mediana de $M2017$ ($\overline{x}_{2017}$ - $\overline{m}_{2017} = 0,5378$) é ainda menor que a mesma diferença para $M2016$ ($\overline{x}_{2016}$ - $\overline{m}_{2016} = 0,5805$), o que instiga análises ainda mais singulares. As assimetrias apresentadas para as distribuições amostrais do gênero feminino fortalecem os princípios de não-normalidade evidenciados anteriormente.

```{r boxplot, echo = FALSE, fig.height = 2.8, fig.width = 4, fig.align = 'center', fig.cap = 'Boxplots.', fig.pos = 'H'}
# Boxplots
ggplot(data = IMCs, aes(y = "", x = value)) + xlab(expression("IMC (kg/"*"m"^2*")")) + 
    ylab("") + geom_boxplot(lwd = 0.3) + 
    facet_wrap(~variable, scales = 'free') + coord_flip()
```

Por fim, gráficos quantil-quantil foram utilizados para comparar as distribuições de probabilidade de cada uma das amostras (eixo das ordenadas) com uma distribuição normal (eixo das abcissas). Tal análise foi tomada para concluir sobre a normalidade das distribuições, corroborando ou refutando conclusões anteriores. Como esperado, o gráfico Q-Q da amostra masculina de $2016/2$ sugere que os dados são normalmente distribuídos, uma vez que a reta se ajusta bem aos pontos (desconsiderando *outliers*). As amostras $M2017$ e $F2016$ também apresentaram bons ajustes do modelo aos dados e, consequentemente, também sugerem normalidade. Quanto à amostra feminina de $2017/2$, há claros sinais de que os dados não seguem uma distribuição normal. Posteriormente, todas essas premissas serão validades a partir de testes estatísticos, como Kolmogorov-Smirnov e Shapiro-Wilk. 

```{r qqplot, echo = FALSE, fig.height = 2.8, fig.width = 4, fig.align = 'center', fig.cap = 'QQ-Plots', fig.pos = 'H'}
# QQ-Plots
ggplot(data = IMCs, aes(sample = value)) +
  facet_wrap(~variable, scales = "free") +
  stat_qq() + stat_qq_line() + scale_y_continuous(name = 'Quantis da Amostra') + 
  scale_x_continuous(name = 'Quantis Teóricos Normais')
```

# Parte 1: Amostras Masculinas

## Tamanho de Efeito

Geralmente, os estudos científicos relatam a significância dos resultados alcançados. Contudo, é aconselhável mensurar também o tamanho de efeito (importância real) pertinente às diferenças encontradas em termos de média ou variância dos grupos avaliados \cite{Kelley2012}. A literatura aborda algumas metodologias para isso, como o Teste de Cohen, Teste de Glass, Teste de Hedges, dentre outros. Cada um desses testes têm diferentes maneiras de calcular o tamanho de efeito quanto a um determinado estimador, alguns fazendo uso da média (Cohen($d$), Glass ($\Delta$), Hedges($g$), $\psi$) e outros a partir das variâncias (Pearson, $\eta^2$, $\omega^2$ e Cohen($f^2$)). O primeiro teste de Cohen mencionado, por exemplo, calcula o tamanho de efeito $d$ quanto à média, obtendo o quociente da diferença entre as médias dos grupos pelo desvio padrão agrupado, conforme a Equação \eqref{eq:d_cohen} \cite{Vieira2003}:

\begin{equation}
  \label{eq:d_cohen}
  d = \frac{\overline{x}_1 - \overline{x}_2}{s} = \frac{\mu_1 - \mu_2}{s}
\end{equation}
onde $\overline{x}_1$ e $\overline{x}_2$ são, respectivamente, as médias das amostras $1$ e $2$ e $s$ é o desvio padrão agrupado dado pela Equação \eqref{eq:desvio_conjugado}:

\begin{equation}
  \label{eq:desvio_conjugado}
  s = \sqrt{\frac{(n_1-1)s^2_1 + (n_2-1)s^2_2}{n_1+n_2 - 2}}
\end{equation}
em que $n_1$ e $n_2$ são, nessa ordem, os tamanhos amostrais dos grupos $1$ e $2$, bem como $s_1$ e $s_2$ são os seus respectivos desvios amostrais.

A medida mais usada para calcular o tamanho de efeito para um teste t de Student é o $d$ de Cohen \cite{Alboukadel2020}. A interpretação deste teste se dá a partir do $d$ calculado pela Equação \eqref{eq:d_cohen} conforme a seguinte classificação \cite{Sawilowsky2009}:

\begin{multicols}{2}
  \begin{itemize}
    \item Muito pequeno: $0,01 \leq d < 0,20$
    \item Pequeno: $0,20 \leq d < 0,50$
    \item Médio: $0,50 \leq d < 0,80$
    \item Grande: $0,80 \leq d < 1,20$
    \item Muito grande: $1,20 \leq d < 2$
    \item Enorme: $d \geq 2,0$
  \end{itemize}
\end{multicols}

Para calcular o tamanho de efeito usando este método, algumas premissas devem ser assumidas sobre os dados: normalidade e homocedasticidade \cite{Peng2014}. Usando o Teste de Shapiro-Wilk é possível inferir sobre a normalidade das amostras, tendo em vista que a hipótese nula $H_0$ deste teste é de que os dados provêm de uma distribuição normal \cite{ShapiroWilkTest}. A função `shapiro.test` do pacote `stats` do R considera o nível de confiança de $90\%$ ($\alpha = 0,1$) para avaliação das amostras fornecidas \cite{ShapiroTestR}. A validação da homocedasticidade será realizada a posteriori, uma vez que a premissa de alguns dos testes capazes de verificar tal premissa assumem normalidade.

O Teste de Shapiro-Wilk evidenciou que as amostras do grupo masculino $M2016$ e $M2017$ provêm de uma distribuição populacional com caráter normal ao nível de confiança de $90\%$, pois a hipótese nula desse teste não pôde ser refutada. Nesse caso, o valor de $p$ resultou em $0,1275$ e $0,6206$, respectivamente, ambos superiores ao nível de significância $\alpha = 0,1$.

```{r, echo = FALSE}
shapiro.test(M2016)
shapiro.test(M2017)
```

Uma vez que as variâncias populacionais não são conhecidas, nada se pode afirmar a cerca da homocedasticidade (igualdade de variâncias). Por isso, torna-se necessário a realização de um teste específico, como o Teste F para igualdade de variâncias. Esse teste tem como hipótese nula a proposição de que os grupos comparados resultam de populações com a mesma variância, partindo do pressuposto de que os dados são normais. O teste estatístico F é calculado pelo quociente da variância do primeiro grupo pelo segundo. Se a resultante de $F$ é maior que o valor crítico superior ou menor que o valor crítico inferior, a hipótese nula é rejeitada \cite{Fang2018}.

```{r, echo = FALSE}
# Teste F: homocedasticidade das amostras masculinas (assume normalidade)
var.test(x = M2016, y = M2017, alternative = "two.sided")
```

A execução do teste F para o grupo de dados $M2016$ e $M2017$ resultou em $F=1,5838$ e $p = 0,3119$, que reflete que a igualdade de variância pode ser assumida para os dados em questão. 

Com isso, pode-se calcular o $d$ de Cohen como uma boa estimativa de tamanho de efeito para as amostras masculinas. O pacote `effsize` do R \cite{Torchiano2020} permite tal cálculo a partir da função `cohen.d`. 

```{r, results = 'hide', echo = FALSE}
# Variáveis
n_1 = length(M2016)
n_2 = length(M2017)
x_1 = mean(M2016)
x_2 = mean(M2017)
s_1 = sd(M2016)
s_2 = sd(M2017)

# Desvio padrão conjugado
s = sqrt(((n_1-1)*s_1^2 + (n_2-1)*s_2^2)/(n_1+n_2-2))
# d de Cohen
d = (x_1 - x_2)/s
```

```{r, echo = FALSE}
cohen.d(sort(M2016),sort(M2017))
```
\noindent O tamanho de efeito reportado é $d = 0,1665$.

## Poder do Teste

No entanto, o cálculo anterior não leva em consideração a potência desejada ($\pi = 0,80$) e nem o nível de significância estipulado ($\alpha = 0,05$). É bem provável que, com essas especificações e com os tamanhos amostrais consideravelmente pequenos ($n_M = n_{M2016} = n_{M2017} = 21$), não seja possível detectar desvios no IMC médio masculino de $0,1665 \ kg/m^2$ a partir das hipóteses de teste, conforme sugere o cálculo do $d$ de Cohen. 

Supondo o desvio padrão conjugado $s_M = 3,9046$ calculado a partir da Equação \eqref{eq:desvio_conjugado}, o nível de significância $\alpha = 0,05$, o tamanho amostral $n_M$ e o $d$ de Cohen calculado anteriormente, a potência obtida pelo método `power.t.test` é de apenas $3,4\%$. Tal valor é cerca de $76,6$ p.p menor que a potência desejada e, portanto, não é aceitável para realização dos experimentos.

```{r, echo = FALSE}
power.t.test(n = 21, sd = 3.904637, sig.level = 0.05, delta = 0.1665831, 
             type = "two.sample", alternative = "two.sided")
```

Para que fosse possível detectar efeitos iguais ou maiores que $d = 0,1665$ de forma a preservar os parâmetros experimentais desejados, seriam necessárias cerca de $8626$ amostras para cada um dos semestres.

```{r, echo = FALSE}
power.t.test(delta = 0.1665831, sd = s, sig.level = 0.05, power = 0.80, 
             type = "two.sample", alternative = "two.sided")
```

Como não existem possibilidades de se obter mais amostras para os experimentos, é possível detectar, a um nível de significância $\alpha = 0,05$ e potência $\pi = 0,80$, um tamanho de efeito de mínima relevância prática de $d = 3,4596$.

```{r, echo = FALSE}
power.t.test(n = 21, sd = 3.904637, sig.level = 0.05, power = 0.80, 
             type = "two.sample", alternative = "two.sided")
```

## Análise Estatística

Uma vez que as premissas de normalidade e homocedasticidade foram validadas, o teste estatístico t de Student pode ser efetuado para comparação das médias. A hipótese nula é que a média da variável estudada (IMC) é igual nas duas populações, ou seja, a diferença entre a média das duas populações é igual a zero. Já a hipótese alternativa indica que há diferenças nas médias das populações, ou seja, $\mu_{2016} - \mu_{2017} \neq 0$. O nível de confiança adotado para os testes foi de $95\%$.

```{r, echo = FALSE}
(t_test <- t.test(x = M2016, 
                  y = M2017,
                  var.equal = TRUE,
                  alternative = "two.sided",
                  conf.level = 0.95))
```
O resultado do teste t de Student retornou um p-valor de $0,5923$, maior que o nível de significância de $0,05$. Assim, com $95\%$ de confiança não é possível rejeitar a hipótese nula $H_0$ de que as médias das duas populações são iguais. Sendo a hipótese alternativa $H_1$ bilateral, o intervalo de confiança para a diferença das médias é $[-1,784943; \ 3,085836]$. É interessante ressaltar que o resultado para o teste t de Welch foi bastante similar em termos de p-valor e intervalo de confiança e, portanto, também falhou em rejeitar a hipótese nula.

# Parte 2: Amostras Femininas

## Análise Estatística

De forma a verificar as premissas de normalidade para as amostras femininas, foram realizados testes de Shapiro-Wilk para ambas amostras com um nível de significância de $\alpha = 0,10$ \cite{ShapiroWilkTest}.

```{r, echo = FALSE}
shapiro.test(na.omit(F2016))
shapiro.test(na.omit(F2017))
```

No que se refere à amostra feminina do semestre $2016/2$, cujo tamanho amostral é $n_{F2016} = 7$, não é possível rejeitar a hipótese nula de que a amostra proveio de uma população com distribuição normal ao nível de confiança de $90\%$ ($p > \alpha)$. Quanto a amostra feminina de $2017/2$, cujo tamanho amostral é $n_{F2017} = 4$, não se pode afirmar o mesmo, uma vez que a hipótese nula é rejeitada ao nível de confiança de $90\%$ ($p < \alpha$). Em outras palavras, pode-se afirmar com $90\%$ de confiança que $F2016$ provém de uma população normal e $F2017$ não.

Com o intuito de averiguar também a premissa de homocedasticidade, utilizou-se o teste de Fligner-Killeen \cite{FlignerKilleenTest}, que não pressupõe amostras provenientes de população com distribuição normal. A hipótese nula desse teste é de que as variâncias das duas populações, das quais foram retiradas as amostras testadas, são iguais. Já a hipótese alternativa é de que essas varianças não são iguais. 

```{r, echo = FALSE}
# Teste de Fligner-Killeen: homocedasticidade das amostras femininas (não assume normalidade)
F <- as.data.frame(cbind(F2016, F2017))
F <- melt(F, na.rm = TRUE, id.vars = NULL)
fligner.test(value ~ variable, data = F)
```
Assim, a partir do p-valor substancialmente maior que o nível de significância, pode-se afirmar que não é possível refutar a hipótese nula ao nível de confiança de $95\%$ e, consequentemente, as amostras provêm de populações homocedásticas.

Por fim, o teste de Wilcoxon para amostras independentes foi definido para análise das populações femininas, uma vez que ele não pressupõe normalidade das amostras. Tal teste é não-paramétrico, equivalente ao teste Mann-Whitney quando as amostras não são pareadas, e sua hipótese nula é de que as medianas das populações são iguais. A hipótese alternativa é de que as medianas populacionais são diferentes. 
```{r, echo = FALSE}
(wilcox_test <- wilcox.test(x = na.omit(F2016), 
                            y = na.omit(F2017), 
                            alternative = "two.sided",
                            paired = FALSE,
                            conf.int = TRUE))
cat('Intervalo de confiança:', wilcox_test$conf.int)
```
Como o p-valor retornado foi maior que o nível de significância do experimento, $0,07273 > 0,05$, a hipótese nula $H_0$ não pôde ser rejeitada ao nível de confiança de $95\%$. O intervalo de confiança bilateral para a diferença das medianas é $[-0,6374374; \ 5,22844]$.

## Tamanho de Efeito

Diferentemente do cálculo realizado quanto às amostras masculinas, no qual o método de d de Cohen pôde ser utilizado, ele não é adequado para estimação do tamanho de efeito das amostras femininas, pois $F2017$ não apresenta características de normalidade, como mostrado pelo teste de Shapiro Wilk. Devido a isso, outras abordagens presentes da bibliografia foram examinadas, dentre elas uma medida baseada em probabilidade, conhecida como $A$ ou estatística não paramétrica do tamanho do efeito da linguagem comum ($CL$), que não é sensível à não normalidade dos dados ou diferença de variâncias, como o d de Cohen \cite{Ruscio2008}.

A medida $A$ está intimamente relacionada a outras medidas estatísticas que usam apenas dados ordinais para estimar a diferença entre dois grupos, incluindo as estatísticas de teste não paramétrico Wilcoxon Rank Sum e Mann-Whitney U, bem como a área sob uma curva de característica de operação do receptor ($ROC$) calculada usando o método trapezoidal de Hanley & McNeil de 1982 \cite{Ruscio2008}.

O valor de $A$ pode ser calculado a partir do $U$ obtido pelo teste de Mann–Whitney \cite{Ruscio2008}, conforme mostrado na equação \ref{eq:A_Measure}. Como nesta aplicação foi utilizado uma equivalência deste teste, U pode ser obtido a partir da estatística do teste de Wilcoxon, como mostrado em sequência.

$A$ está relacionado aos teste de Mann-Whitney e Wilcoxon pois, em outras palavras, ele representa a probabilidade de X1 ser maior que X2 mais $50\%$ da probabilidade de X1 ser igual a X2, sendo X1 e X2 as amostras ou população que estão sendo comparadas. E $U$ é a probabilidade de X1 ser menor que X2 mais $50\%$ da probabilidade de X1 = X2 \cite{Ruscio2008}.

Em situações onde os dados são paramétricos e homocedásticos é possível converter o parâmetro A na medida estatística do d de Cohen \cite{Ruscio2008} , que não é aplicável neste contexto.

\begin{equation}
\label{eq:A_Measure}
A = \frac{n_1 n_2-U}{n_1 n_2}
\end{equation}
onde $U = n_1 n_2 - W$, sendo $W = 24$, reportado pela função `wilcox.test` em R \cite{Ruscio2008}.

Na equação \ref{eq:A_Measure}, n1 e n2 são os tamanhos amostrais de $F2016$ e $F2017$, respectivamente. Sendo assim, ao resolve-la, obtém-se $A =  0,8571429$. 

O mesmo valor pode ser encontrado a partir da execução do teste de $Vargha \& Delaney$, `VD.A` em R \cite{Delaney2002}. Esta função também retorna o valor de uma avaliação qualitativa da magnitude do tamanho do efeito, sendo este igual a $4$.


```{r, echo = FALSE}
(vd_a <- VD.A(na.omit(F2016), na.omit(F2017)))

cat('Magnitude:', vd_a$magnitude)
```
A medida $A$ é um valor entre $0$ e $1$ quando aplicada a duas populações: quando a medida $A$ é exatamente $0,5$, então as duas populações tem diferenças igual a zero. Quando $A$ é menor que $0,5$, a primeira tem valores menores, e quando $A$ é maior que $0,5$, a segunda tem valores menores. Quanto mais próximo de $0,5$, menor a diferença entre as populações, e quanto mais distante de $0,5$, maior a diferença \cite{vargha2000}.
Em $85\%$ das vezes, alunas de $2016/2$ têm maior mediana do índice de massa corporal que as alunas do $2017/2$, podendo encontrar diferencas maior que $4 (kg/m²)$, haja vista que a avaliação qualitativa do tamanho de efeito é ($4 (kg/m²)$).


## Poder do Teste

A falta de normalidade dos dados também impede a aplicação da função power.t.test para análise estatística das amostras femininas, nesse caso, o apropriado é calcular o poder do teste a partir de derivações do teste de Wilcoxon. No R existem algumas possibilidades dentro do pacote ‘wmwpow’ \cite{wmwpow}, são elas: calcular o poder usando a abordagem de Shieh et. Al  \cite{shieh2006power} e o método de Monte Carlo. Todavia, ambas as abordagens requerem que o tipo de distribuição seja passado por parâmetro, e portanto, conhecido previamente. Em vista disso, o cálculo do poder não pôde ser aplicado, pois o tipo de distribuição não pôde ser estabelecido devido ao baixo tamanho amostral.

Dado que os tamanhos amostrais são distintos ($n_{F2016} \neq n_{F2017}$) e extremamente pequenos, é bem provável que a potência para efeitos maiores ou iguais a $A = 0,8571$ seja substancialmente menor que a desejada ($\pi = 0,80$).


```{r, results = 'hide', echo = FALSE}
# Variáveis
n_1 = length(na.omit(F2016))
n_2 = length(na.omit(F2017))
x_1 = mean(na.omit(F2016))
x_2 = mean(na.omit(F2017))
s_1 = sd(na.omit(F2016))
s_2 = sd(na.omit(F2017))

# Desvio padrão conjugado
s = sqrt(((n_1-1)*s_1^2 + (n_2-1)*s_2^2)/(n_1+n_2-2))
```


# Conclusões

Com o objetivo de comparar o Índice de Massa Corpórea (IMC) médio de duas populações de estudantes do Programa de Pós Graduação em Engenharia Elétrica da Universidade Federal de Minas Gerais (PPGEE UFMG), segundo semestre de 2016 e segundo de 2017, foram utilizados conceitos e ferramentas estatísticas para inferir sobre IMC médio dessas populações. Para facilitar o estudo, as amostras foram separadas entre masculino e feminino, e só então foram comparados os IMCs masculino de 2016/2 e 2017/2, feminino de 2016/2 e 2017/2. 

A distribuição das amostras masculinas de ambos períodos tem características normais e de homocedacidade, conforme explorado graficamente e comprovado via testes. Sobre esta população conclui-se com $95\%$ de confiança que as médias das duas populações são iguais, visto que não se pôde rejeitar a hipotese nula $H0$. Nesse contexto, para atender os $95\%$ de confiança e a potência de $80\%$, o tamanho de efeito deveria ser capaz de identificar diferenças maiores que $3,90 (Kg/m^2)$, porém a ferramenta de cálculo $d$ de Cohen estimou que era possivel identificar diferenças maiores que $0,16 (Kg/m^2)$. Contudo, este tamanho de efeito não permite atender ao poder do teste especificado, pois a potência do teste obtida foi igual a $0,034(Kg/m^2)$. Para manter a mesma potência do teste, $80\%$, seria necessário um tamanho amostral igual a 8626.

Já a distribuição da amostra feminina do segundo semestre de 2017 comporta de forma não normal, enquanto que amostra feminina do segundo semestre de 2016 segue normalidade, e ambas são homocedadicas entre si. Como uma das amostras femininas não segue distribuição normal, optou-se pela utilização de testes não parametricos. Por causa disso, a análise foi feita sobre a mediana, e o teste permitiu concluir com $95%$ de confiança que as populações femininas têm medianas iguais, e é possivel observar diferenças maiores que $4 (Kg/m²)$.

## Discussão de Melhorias
O pequeno tamanho amostral das amostras femininas apresentar ser o principal fator que contribuiu para a não normalidade dos dados e consequentemente sugeriu a utilização de testes não paramétricos. E mesmo de posse desses testes, não foi possível calcular o poder do teste por não haver evidências suficientes para inferir sobre a distribuição amostral, que era uma das premissas necessárias para utilização do teste utilizado para esta finalidade. Dessa forma, a obtenção de mais amostras contribui diretamente para que mais premissas possam ser validadas, e tende a aumentar o repertório de testes e métodos que podem ser utilizados para validações estatísticas.

## Atividades Desempenhadas

As hipóteses de teste para ambos experimentos foram definidas em concordância com os três autores. Em relação à primeira parte do estudo de caso, tanto o pré-processamento dos dados, quanto a análise exploratória e o poder do teste foram conduzidos pelo Pedro. A Samara realizou o cálculo do tamanho de efeito e a validação das premissas assumidas para os testes estatísticos. A análise estatística, por sua vez, foi feita pelo Sávio. A segunda parte do estudo de caso, referente às inferências sobre a distribuição feminina, foi realizada após sucessivas investigações. A análise estatística foi novamente realizada pelo Sávio e o cálculo do tamanho de efeito, bem como a validação das premissas inerentes, foram conduzidas em conjunto. Por fim, o Pedro realizou a análise de potência do teste e a Samara conclui o trabalho com as considerações finais e discussões de melhoria.

\renewcommand\refname{Referências}
\bibliographystyle{plain}
\bibliography{ref}